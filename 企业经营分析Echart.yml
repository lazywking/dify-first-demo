app:
  description: Áî®‰∫é‰ºÅ‰∏öÁªèËê•ÂàÜÊûêÊä•ÂëäÁöÑÁîüÊàê
  icon: ü§ñ
  icon_background: '#FFEAD5'
  mode: advanced-chat
  name: ‰ºÅ‰∏öÁªèËê•ÂàÜÊûêEchart
  use_icon_as_answer_icon: false
dependencies:
- current_identifier: null
  type: marketplace
  value:
    marketplace_plugin_unique_identifier: langgenius/ollama:0.0.3@9ded90ac00e8510119a24be7396ba77191c9610d5e1e29f59d68fa1229822fc7
- current_identifier: null
  type: marketplace
  value:
    marketplace_plugin_unique_identifier: langgenius/xinference:0.0.3@2f59f67f45ca4f626aaeef0d9c656cc0e38ab9fbf2c9b4673e3e20162eed9e4f
kind: app
version: 0.1.5
workflow:
  conversation_variables: []
  environment_variables: []
  features:
    file_upload:
      allowed_file_extensions:
      - .JPG
      - .JPEG
      - .PNG
      - .GIF
      - .WEBP
      - .SVG
      allowed_file_types:
      - image
      allowed_file_upload_methods:
      - local_file
      - remote_url
      enabled: false
      fileUploadConfig:
        audio_file_size_limit: 50
        batch_count_limit: 5
        file_size_limit: 15
        image_file_size_limit: 10
        video_file_size_limit: 100
        workflow_file_upload_limit: 10
      image:
        enabled: false
        number_limits: 3
        transfer_methods:
        - local_file
        - remote_url
      number_limits: 3
    opening_statement: ''
    retriever_resource:
      enabled: true
    sensitive_word_avoidance:
      enabled: false
    speech_to_text:
      enabled: false
    suggested_questions: []
    suggested_questions_after_answer:
      enabled: false
    text_to_speech:
      enabled: false
      language: ''
      voice: ''
  graph:
    edges:
    - data:
        isInLoop: false
        sourceType: knowledge-retrieval
        targetType: llm
      id: 1745384923228-source-llm-target
      source: '1745384923228'
      sourceHandle: source
      target: llm
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: start
        targetType: llm
      id: 1745372530859-source-1745385774081-target
      source: '1745372530859'
      sourceHandle: source
      target: '1745385774081'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: llm
        targetType: knowledge-retrieval
      id: 1745385774081-source-1745384923228-target
      source: '1745385774081'
      sourceHandle: source
      target: '1745384923228'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: llm
        targetType: code
      id: llm-source-1745823859913-target
      source: llm
      sourceHandle: source
      target: '1745823859913'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: code
        targetType: code
      id: 1745823859913-source-1745819871323-target
      source: '1745823859913'
      sourceHandle: source
      target: '1745819871323'
      targetHandle: target
      type: custom
      zIndex: 0
    - data:
        isInIteration: false
        isInLoop: false
        sourceType: code
        targetType: answer
      id: 1745819871323-source-1745895911042-target
      source: '1745819871323'
      sourceHandle: source
      target: '1745895911042'
      targetHandle: target
      type: custom
      zIndex: 0
    nodes:
    - data:
        desc: ''
        selected: false
        title: ÂºÄÂßã
        type: start
        variables: []
      height: 54
      id: '1745372530859'
      position:
        x: 43
        y: 129
      positionAbsolute:
        x: 43
        y: 129
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: true
          variable_selector:
          - '1745384923228'
          - result
        desc: ''
        memory:
          query_prompt_template: '{{#sys.query#}}'
          role_prefix:
            assistant: ''
            user: ''
          window:
            enabled: true
            size: 10
        model:
          completion_params: {}
          mode: chat
          name: deepseek-r1:8b
          provider: langgenius/ollama/ollama
        prompt_template:
        - id: 17c74b78-c052-4098-9224-b4e89402be2b
          role: system
          text: "# Role: ËµÑÊ∑±ÁªèËê•ÂàÜÊûêÂ∏à AI\n\n# Context / Input Data Types (‰æõ‰Ω†ÁêÜËß£ÂèØËÉΩÁöÑ‰ø°ÊÅØÊù•Ê∫ê):\n\
            {{#context#}}\n  - Ë¥¢Âä°Êï∞ÊçÆÔºöÂ¶ÇÊî∂ÂÖ•„ÄÅÊàêÊú¨„ÄÅÊØõÂà©Áéá„ÄÅÂáÄÂà©Áéá„ÄÅÁé∞ÈáëÊµÅÁ≠âÔºàÂèØËÉΩÂåÖÂê´Êó∂Èó¥Â∫èÂàóÊï∞ÊçÆÔºâ\n  - Â∏ÇÂú∫Êï∞ÊçÆÔºöÂ¶ÇÈîÄÂîÆÈáè„ÄÅÈîÄÂîÆÈ¢ù„ÄÅÂÆ¢Êà∑Êï∞Èáè„ÄÅÊñ∞ÂÆ¢Êà∑„ÄÅÂ§çË¥≠Áéá„ÄÅÂ∏ÇÂú∫‰ªΩÈ¢ù„ÄÅNPS\
            \ Á≠âÔºàÂèØËÉΩÂàÜÂå∫Âüü„ÄÅ‰∫ßÂìÅ„ÄÅÊ∏†ÈÅìÔºâ\n  - ËøêËê•Êï∞ÊçÆÔºöÂ∫ìÂ≠òÊ∞¥Âπ≥„ÄÅÂë®ËΩ¨Â§©Êï∞„ÄÅ‰æõÂ∫îÈìæÊïàÁéá„ÄÅÁîü‰∫ßÊåáÊ†áÁ≠â\n  - Â§ñÈÉ®ÁéØÂ¢ÉÔºöË°å‰∏öÂ¢ûÈïøÁéá„ÄÅ‰∏ªË¶ÅÁ´û‰∫âÂØπÊâãË°®Áé∞„ÄÅÊîøÁ≠ñÊ≥ïËßÑÂèòÂåñ„ÄÅÂÆèËßÇÁªèÊµéÊåáÊ†áÁ≠â\n\
            \  - ÂÆöÊÄßÊ¥ûÂØüÔºöÁÆ°ÁêÜÂ±ÇËßÇÁÇπ„ÄÅÂÆ¢Êà∑ÂèçÈ¶àÊëòË¶Å„ÄÅÂëòÂ∑•Êª°ÊÑèÂ∫¶Ë∞ÉÊü•ÂÖ≥ÈîÆÁÇπÁ≠â\n\n# User Input:\n\n\n**‰ªªÂä°Ë¶ÅÊ±Ç (Task\
            \ Requirements)**Ôºö\n1.  Âü∫‰∫éÁî®Êà∑Êèê‰æõÁöÑ {{#sys.query#}}Âíå‰Ω†ÁöÑËÉåÊôØÁü•ËØÜÔºåÁîüÊàê‰∏Ä‰ªΩÁªìÊûÑÂåñÁöÑÁªèËê•ÂàÜÊûêÊä•Âëä„ÄÇ\n\
            2.  Êä•ÂëäÂÜÖÂÆπÂ∫îËá≥Â∞ëÂåÖÂê´‰ª•‰∏ãÈÉ®ÂàÜÔºàÊ†πÊçÆÂÆûÈôÖÊï∞ÊçÆÂíåÂàÜÊûêÈúÄË¶ÅË∞ÉÊï¥ÔºâÔºö\n    *   **ÊëòË¶Å (Summary):** ÂÖ≥ÈîÆ‰∏öÁª©ÊåáÊ†á (KPIs)\
            \ Ê¶ÇËßà„ÄÅÊ†∏ÂøÉÂèëÁé∞Âíå‰∏ªË¶ÅÁªìËÆ∫„ÄÇ\n    *   **Ë¥¢Âä°ÂàÜÊûê (Financial Analysis):** ÂàÜÊûêÊî∂ÂÖ•„ÄÅÂà©Ê∂¶„ÄÅÊàêÊú¨„ÄÅÂÖ≥ÈîÆË¥¢Âä°ÊØîÁéáÁ≠âÔºå**ÂøÖÈ°ªÂåÖÂê´Ë∂ãÂäøÂàÜÊûê**ÔºàÂ¶ÇÂêåÊØî„ÄÅÁéØÊØîÂ¢ûÈïøÔºâ„ÄÇ\n\
            \    *   **Â∏ÇÂú∫‰∏éÈîÄÂîÆÂàÜÊûê (Market & Sales Analysis):** ÂàÜÊûêÈîÄÂîÆË°®Áé∞ÔºàÊåâÂå∫Âüü/‰∫ßÂìÅ/Ê∏†ÈÅìÔºâ„ÄÅÂÆ¢Êà∑Ë°å‰∏∫ÔºàNPS„ÄÅÂ§çË¥≠„ÄÅÊäïËØâÔºâ„ÄÅÂ∏ÇÂú∫‰ªΩÈ¢ùÔºàÂ¶ÇÊûú‰ø°ÊÅØÂèØÁî®ÔºâÁ≠â„ÄÇ\n\
            \    *   **ËøêËê•ÂàÜÊûê (Operational Analysis):** ÔºàÂ¶ÇÊûúÊï∞ÊçÆÂèØÁî®ÔºâÂàÜÊûêÂ∫ìÂ≠ò„ÄÅ‰æõÂ∫îÈìæÁ≠âËøêËê•ÊïàÁéáÊåáÊ†á„ÄÇ\n \
            \   *   **Â§ñÈÉ®ÁéØÂ¢É‰∏éÈ£éÈô©ÂàÜÊûê (External Environment & Risk Analysis):** ÂàÜÊûêË°å‰∏öË∂ãÂäø„ÄÅÁ´û‰∫âÊ†ºÂ±Ä„ÄÅÊîøÁ≠ñÂΩ±Âìç„ÄÅÂÆèËßÇÁªèÊµéÂõ†Á¥†‰ª•ÂèäËØÜÂà´ÊΩúÂú®È£éÈô©„ÄÇ\n\
            \    *   **ÂÆöÊÄßÊ¥ûÂØü (Qualitative Insights):** ÔºàÂ¶ÇÊûú‰ø°ÊÅØÂèØÁî®ÔºâÊï¥ÂêàÁÆ°ÁêÜÂ±Ç„ÄÅÂÆ¢Êà∑„ÄÅÂëòÂ∑•ÁöÑÂÖ≥ÈîÆÂèçÈ¶àÊàñËßÇÁÇπ„ÄÇ\n\
            \    *   **ÁªìËÆ∫‰∏éÂª∫ËÆÆ (Conclusion & Recommendations):** Âü∫‰∫é‰ª•‰∏äÂàÜÊûêÔºåÊèêÂá∫ÂÖ∑‰ΩìÁöÑ„ÄÅÂèØË°åÁöÑÊîπËøõÂª∫ËÆÆÊàñÊàòÁï•ÊñπÂêë„ÄÇ\n\
            3.  **ËØÜÂà´Êä•Âëä‰∏≠ÈÄÇÂêàÈÄöËøáÂõæË°®ÂèØËßÜÂåñÁöÑÂÖ≥ÈîÆÊï∞ÊçÆÁÇπ**Ôºå‰æãÂ¶ÇÔºö\n    *   Êó∂Èó¥Â∫èÂàóË∂ãÂäøÔºàÂ¶ÇÊî∂ÂÖ•/Âà©Ê∂¶ÈöèÊó∂Èó¥ÂèòÂåñÔºâ -> **ÊäòÁ∫øÂõæ\
            \ (line)**\n    *   ÊûÑÊàêÊàñÂç†ÊØîÔºàÂ¶ÇÂå∫Âüü/‰∫ßÂìÅÈîÄÂîÆÈ¢ùÂç†ÊØîÔºâ -> **È•ºÂõæ (pie)**\n    *   ÂàÜÁ±ªÊØîËæÉÔºàÂ¶Ç‰∏çÂêå‰∫ßÂìÅÁ∫øÁöÑÈîÄÂîÆÈ¢ù„ÄÅÂÖ¨Âè∏‰∏éË°å‰∏öÂ¢ûÈïøÁéáÂØπÊØîÔºâ\
            \ -> **Êü±Áä∂Âõæ (bar)**\n4.  **‰∏∫ÊØè‰∏™ÈúÄË¶ÅÁîüÊàêÁöÑÂõæË°®ÔºåËæìÂá∫ÁªìÊûÑÂåñÁöÑÊï∞ÊçÆÂØπË±°**„ÄÇÊ≠§ÂØπË±°Â∫îÂåÖÂê´Ôºö\n    *   `chart_id`:\
            \ ‰∏Ä‰∏™Áã¨ÁâπÁöÑÊ†áËØÜÁ¨¶Ôºà‰æãÂ¶Ç \"income_trend_q1_2024\"Ôºâ„ÄÇ\n    *   `title`: ÂõæË°®ÁöÑÊ†áÈ¢òÔºà‰æãÂ¶Ç \"\
            2024Âπ¥Q1Êî∂ÂÖ•Ë∂ãÂäø\"Ôºâ„ÄÇ\n    *   `type`: ÂõæË°®Á±ªÂûã ('line', 'bar', 'pie')„ÄÇ\n    * \
            \  `data`: ÂåÖÂê´ÂõæË°®ÊâÄÈúÄÁöÑÊï∞ÊçÆÔºåÁªìÊûÑÂ¶Ç‰∏ãÔºö\n        *   `labels`: ‰∏Ä‰∏™ÂåÖÂê´Á±ªÁõÆÊ†áÁ≠æÊàñÊó∂Èó¥ÁÇπÁöÑÊï∞ÁªÑ (e.g.,\
            \ `[\"2023 Q4\", \"2024 Q1\"]`)„ÄÇ\n        *   `datasets`: ‰∏Ä‰∏™ÂåÖÂê´‰∏Ä‰∏™ÊàñÂ§ö‰∏™Êï∞ÊçÆÈõÜÂØπË±°ÁöÑÊï∞ÁªÑ„ÄÇÊØè‰∏™Êï∞ÊçÆÈõÜÂØπË±°Â∫îÂåÖÂê´Ôºö\n\
            \            *   `label`: Êï∞ÊçÆÁ≥ªÂàóÁöÑÂêçÁß∞ (e.g., \"Êî∂ÂÖ•(‰∏áÂÖÉ)\")„ÄÇ\n            * \
            \  `values`: ‰∏é `labels` ÂØπÂ∫îÁöÑÊï∞ÂÄºÊï∞ÁªÑ (e.g., `[4800, 5000]`)„ÄÇ\n            *\
            \   (ÂØπ‰∫éÈ•ºÂõæÔºåÈÄöÂ∏∏Âè™Êúâ‰∏Ä‰∏™ datasetÔºåvalues Áõ¥Êé•ÂØπÂ∫î labels ÁöÑÂç†ÊØîÊàñÊï∞ÂÄº)„ÄÇ\n5.  Âú®Êä•ÂëäÁöÑ Markdown\
            \ ÊñáÊú¨ÈÉ®ÂàÜÁöÑÈÄÇÂΩì‰ΩçÁΩÆÔºå‰ΩøÁî® `[CHART: chart_id]` Ê†ºÂºè**ÊèíÂÖ•ÂõæË°®Âç†‰ΩçÁ¨¶**ÔºåÊåáÊòéËØ•ÂõæË°®Â∫îÂú®ÊñáÊú¨ÁöÑÂì™‰∏™‰ΩçÁΩÆÂ±ïÁ§∫„ÄÇ`chart_id`\
            \ ÂøÖÈ°ª‰∏é‰∏ãÈù¢ `charts` Êï∞ÁªÑ‰∏≠ÂÆö‰πâÁöÑÂõæË°® ID Áõ∏ÂØπÂ∫î„ÄÇ\n6.  Êä•ÂëäËØ≠Ë®ÄÂ∫î‰∏ì‰∏ö„ÄÅÂÆ¢ËßÇ„ÄÅÁÆÄÊ¥ÅÔºåÈáçÁÇπÁ™ÅÂá∫Êï∞ÊçÆÈ©±Âä®ÁöÑÊ¥ûÂØü (Insights)\
            \ ËÄåÈùûÁÆÄÂçïÁΩóÂàóÊï∞ÊçÆ„ÄÇ\n7.  **ËæìÂá∫Ê†ºÂºè**Ôºö\n- Markdown Ê†ºÂºè\n- ÊØèÈÉ®ÂàÜ‰ª•‰∫åÁ∫ßÊ†áÈ¢òÔºà##ÔºâÂàÜÈöî\n- ÂõæË°®Êï∞ÊçÆÔºöÂ¶ÇÊûúÂàÜÊûêÊâÄÈúÄÂÖ≥ÈîÆÊï∞ÊçÆÂú®Áº∫Â§±ÔºåÂ∫îÂú®Êä•ÂëäÊñáÊú¨‰∏≠Ê†áÊ≥®‚ÄúÔºàÊï∞ÊçÆÁº∫Â§±ÔºåÂª∫ËÆÆË°•ÂÖÖÔºâ‚ÄùÔºåÂπ∂‰∏î**‰∏çË¶Å**‰∏∫Áº∫Â§±Êï∞ÊçÆÁîüÊàêÂõæË°®Êï∞ÊçÆ„ÄÇ\n\
            - ÈúÄË¶ÅÁîüÊàêÂõæË°®Êï∞ÊçÆÁöÑÂøÖÈ°ª‰∏•Ê†ºÊåâÁÖß‰∏ãÈù¢ÁöÑ JSON ÁªìÊûÑËæìÂá∫„ÄÇ** ËæìÂá∫ÂÜÖÂÆπÊòØ‰∏Ä‰∏™ JSON ÂØπË±°ÔºåÂåÖÂê´È°∂Á∫ßÈîÆÔºö`charts`„ÄÇ\n\n\
            ```json\n\n{  \n  \"charts\": [\n    // ËøôÈáåÊòØ‰∏Ä‰∏™ÂåÖÂê´ÊâÄÊúâÂõæË°®Êï∞ÊçÆÂØπË±°ÁöÑÊï∞ÁªÑ\n    {\n  \
            \    \"chart_id\": \"...\",\n      \"title\": \"...\",\n      \"type\"\
            : \"...\", // 'line', 'bar', 'pie'\n      \"data\": {\n        \"labels\"\
            : [...],\n        \"datasets\": [\n          { \"label\": \"...\", \"\
            values\": [...] },\n          // ÂèØËÉΩÊúâÊõ¥Â§ö datasets (‰æãÂ¶ÇÔºåÂØπÊØîÊü±Áä∂Âõæ)\n        ]\n\
            \      }\n    },\n    // ... ÂÖ∂‰ªñÂõæË°®ÂØπË±°\n  ]\n}\n```\n\n**Á§∫‰æãËæìÂá∫**Ôºö\n```markdown\n\
            # ABC Èõ∂ÂîÆÂÖ¨Âè∏ 2024 Q1 ÁªèËê•ÂàÜÊûêÊä•Âëä\n\n## ÊëòË¶Å\n- Êî∂ÂÖ• 5000 ‰∏áÂÖÉÔºåÂêåÊØîÂ¢ûÈïø 13.6%„ÄÇ\n- Âçé‰∏úÂú∞Âå∫ÈîÄÂîÆÂç†ÊØî\
            \ 50%ÔºåÂ§çË¥≠Áéá 70%„ÄÇ\n- Ë°å‰∏öÂ¢ûÈïøÁéá 5%ÔºåÂèóÊñ∞Á®éÊî∂ÊîøÁ≠ñÂΩ±Âìç„ÄÇ\n\n## Ë¥¢Âä°ÂàÜÊûê\n- Êî∂ÂÖ•Ôºö5000 ‰∏áÂÖÉÔºåÊØõÂà©Áéá 30%ÔºåÂáÄÂà©Áéá\
            \ 10%„ÄÇ\n- Ë∂ãÂäøÔºö2023 Q4 Êî∂ÂÖ• 4800 ‰∏áÂÖÉÔºåÂ¢ûÈïøÁ®≥ÂÆö„ÄÇ\n- ÊäòÁ∫øÂõæÂ±ïÁ§∫Êî∂ÂÖ•Ë∂ãÂäøÔºö\n```json\n{  \n  \"\
            charts\": [  \n    {\n      \"chart_id\": \"...\",\n      \"title\": \"\
            Êî∂ÂÖ•Ë∂ãÂäø\",\n      \"type\": \"line\", \n      \"data\": {\n        \"labels\"\
            : [...],\n        \"datasets\": [\n          { \"label\": \"...\", \"\
            values\": [...] },          \n        ]\n      }\n    },   \n  ]\n}\n\
            ```\n\n## Â∏ÇÂú∫ÂàÜÊûê\n- ÈîÄÂîÆÔºöÊúçË£ÖÁ∫ø‰∏äÈîÄÂîÆ 2000 ‰∏áÂÖÉÔºåNPS 60„ÄÇ\n- ÂÆ¢Êà∑Ë°å‰∏∫ÔºöÁâ©ÊµÅÂª∂ËøüÂØºËá¥ÊäïËØâÂ¢ûÂä†„ÄÇ\n- È•ºÂõæÂ±ïÁ§∫Âú∞Âå∫ÈîÄÂîÆÂç†ÊØîÔºö\n\
            ```json\n{  \n  \"charts\": [  \n    {\n      \"chart_id\": \"...\",\n\
            \      \"title\": \"Âú∞Âå∫ÈîÄÂîÆÂç†ÊØî\",\n      \"type\": \"pie\", \n      \"data\"\
            : {\n        \"labels\": [...],\n        \"datasets\": [\n          {\
            \ \"label\": \"...\", \"values\": [...] },          \n        ]\n    \
            \  }\n    },   \n  ]\n}\n```\n\n## Â§ñÈÉ®ÁéØÂ¢ÉÂàÜÊûê\n- Ë°å‰∏öÔºöÈõ∂ÂîÆË°å‰∏öÂ¢ûÈïøÁéá 5%ÔºåÂ∏ÇÂú∫ËßÑÊ®° 5000 ‰∫øÂÖÉ„ÄÇ\n\
            - ÊîøÁ≠ñÔºöÊñ∞ÁîµÂïÜÁ®éÊî∂ÊîøÁ≠ñÂ¢ûÂä†ÊàêÊú¨„ÄÇ\n- Êü±Áä∂ÂõæÂØπÊØîË°å‰∏öÂ¢ûÈïøÁéáÔºö\n```json\n{  \n  \"charts\": [  \n  \
            \  {\n      \"chart_id\": \"...\",\n      \"title\": \"Ë°å‰∏öÂ¢ûÈïøÁéá\",\n    \
            \  \"type\": \"bar\", \n      \"data\": {\n        \"labels\": [...],\n\
            \        \"datasets\": [\n          { \"label\": \"...\", \"values\":\
            \ [...] },          \n        ]\n      }\n    },   \n  ]\n}\n```\n\n##\
            \ Âª∫ËÆÆ\n- ‰ºòÂåñÁâ©ÊµÅÊµÅÁ®ãÔºåÈôç‰ΩéÊäïËØâÁéá„ÄÇ\n- Â¢ûÂä†Âçé‰∏úÂú∞Âå∫Ëê•ÈîÄÊäïÂÖ•„ÄÇ"
        - id: 3b74f39c-7dd7-4096-a8e2-fc823b8d04be
          role: user
          text: '**Áî®Êà∑ÈúÄÊ±Ç**Ôºö{{#sys.query#}}


            '
        selected: false
        title: LLM
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: llm
      position:
        x: 943
        y: 129
      positionAbsolute:
        x: 943
        y: 129
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        dataset_ids:
        - 10e5e7b3-38da-4f5e-b2d8-f2b5434e4ae4
        - 192055fd-5b77-4c4c-bc66-f3af5c4b0727
        - 518f28c9-34ae-4454-8738-e52b50c123c5
        - effef781-1d2b-46e5-9f7a-a8d74c200ac2
        - b285d47f-dfcb-46ed-a187-757fa5196405
        desc: ''
        multiple_retrieval_config:
          reranking_enable: true
          reranking_mode: reranking_model
          reranking_model:
            model: bge-reranker-large
            provider: langgenius/xinference/xinference
          top_k: 4
        query_variable_selector:
        - '1745385774081'
        - text
        retrieval_mode: multiple
        selected: false
        title: Áü•ËØÜÊ£ÄÁ¥¢
        type: knowledge-retrieval
      height: 204
      id: '1745384923228'
      position:
        x: 659
        y: 351
      positionAbsolute:
        x: 659
        y: 351
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        context:
          enabled: false
          variable_selector: []
        desc: ''
        model:
          completion_params: {}
          mode: chat
          name: deepseek-r1:8b
          provider: langgenius/ollama/ollama
        prompt_template:
        - id: d3164bd5-72d2-45e4-bee1-92f9040b50a5
          role: system
          text: "#ËßíËâ≤\n‰Ω†ÊòØ‰∏Ä‰ΩçÊñáÂ≠óÊèêÁÇº‰∏ìÂÆ∂\n#‰ªªÂä°\nÊ†πÊçÆÁªèËê•ÂàÜÊûêÁöÑÊúÄÁªàÁõÆÁöÑÔºåË¥üË¥£ÊääÁî®Êà∑Êü•ËØ¢Êï∞ÊçÆÈúÄÊ±ÇËøõË°åÊèêÁÇºÂíåÊÄªÁªìÔºåÊèêÂèñÊúÄÊ†∏ÂøÉÁöÑÂÖ≥ÈîÆËØçÊàñËÄÖ‰∏ªÈ¢òÔºå‰∏çÈúÄË¶ÅÊèê‰æõËØ¶ÁªÜÁöÑÂõûÁ≠îÊàñËÄÖËß£ÈáäÔºåÂè™ÈúÄË¶ÅÊäìÂèñÂÖ≥ÈîÆÊï∞ÊçÆÊü•ËØ¢ÊñáÂ≠óÔºåÂéªÊéâÂíåÊï∞ÊçÆÊü•ËØ¢Êó†ÂÖ≥ÁöÑÂÜÖÂÆπÔºåÊØîÂ¶ÇÁîüÊàêÂõæÁâá„ÄÅÁîüÊàêExcel„ÄÅÁîüÊàêË°®ÂçïÁ≠âÂíåÊï∞ÊçÆÊü•ËØ¢Êó†ÂÖ≥ÁöÑÂÜÖÂÆπÔºåÂè™‰øùÁïôÊèêÁÇºÊü•ËØ¢Êï∞ÊçÆÁöÑÊñáÂ≠ó„ÄÇ\n\
            #ËæìÂá∫\nÂè™ËæìÂá∫‰Ω†ÊèêÁÇºÂêéÁöÑÁªìÊûúÔºåÂÖ≥ÈîÆËØçÂëºÂè´Âì¶Ëøô‰∏ªÈ¢òÂêçÁß∞Ôºå‰∏çÈúÄË¶ÅÊèê‰æõÂÖ∂‰ªñËß£ÈáäÊàñËÄÖÈôÑÂä†‰ø°ÊÅØÔºå‰ΩÜÊòØÈúÄË¶ÅÂåÖÂê´ÔºåÊØîÂ¶ÇË¥¢Âä°„ÄÅÂ∏ÇÂú∫„ÄÅËøêËê•„ÄÅÂ§ñÈÉ®ÁéØÂ¢É„ÄÅÂÆöÊÄßÂèçÈ¶àËøô‰∫õÂÖ≥ÈîÆËØç\n\
            \n\r"
        - id: f4388a4e-bdf4-4167-a971-d0b7e81f2ad3
          role: user
          text: 'Áî®Êà∑ÁöÑÊü•ËØ¢ÈúÄÊ±Ç

            {{#sys.query#}}'
        selected: false
        title: LLM 2
        type: llm
        variables: []
        vision:
          enabled: false
      height: 90
      id: '1745385774081'
      position:
        x: 359
        y: 351
      positionAbsolute:
        x: 359
        y: 351
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\nimport re # Keep re import\n\ndef main(json_content_strings_input:\
          \ str) -> dict:\n    \"\"\"\n    Parses an input JSON string (representing\
          \ a list of blocks, each containing a 'charts' list),\n    converts each\
          \ individual chart definition found within into an ECharts configuration\
          \ string\n    wrapped in ```echarts``` markdown, collects these outputs,\
          \ and returns\n    them concatenated into a single Markdown string under\
          \ the 'result' key.\n    \"\"\"\n    parsing_errors = []\n    generation_errors\
          \ = []\n    list_of_data_blocks = []\n\n    # 1. Parse the input string\
          \ into a Python list of dictionaries\n    try:\n        parsed_input = json.loads(json_content_strings_input)\n\
          \        if isinstance(parsed_input, list):\n            for i, item in\
          \ enumerate(parsed_input):\n                if isinstance(item, dict):\n\
          \                    if 'charts' in item and isinstance(item['charts'],\
          \ list):\n                         list_of_data_blocks.append(item)\n  \
          \                  else:\n                         parsing_errors.append({\"\
          index\": i, \"error\": \"Item is a dict but missing 'charts' key or 'charts'\
          \ is not a list.\", \"content\": str(item)[:500]})\n                   \
          \      print(f\"Warning: Item at index {i} is a dict but missing 'charts'\
          \ list.\")\n                else:\n                     parsing_errors.append({\"\
          index\": i, \"error\": f\"Item in parsed input list is not a dictionary,\
          \ but {type(item).__name__}\", \"content\": str(item)[:500]})\n        \
          \             print(f\"Warning: Item at index {i} in parsed input list is\
          \ not a dictionary.\")\n        else:\n            parsing_errors.append({\"\
          index\": -1, \"error\": f\"Input parsed but is not a list, type is {type(parsed_input).__name__}\"\
          , \"content\": json_content_strings_input[:1000]})\n            print(f\"\
          Warning: Parsed input is not a list.\")\n\n    except json.JSONDecodeError\
          \ as e:\n        parsing_errors.append({\"index\": -1, \"error\": f\"Input\
          \ string is not valid JSON: {str(e)}\", \"content\": json_content_strings_input[:1000]})\n\
          \        print(f\"Error: Input string could not be parsed as JSON: {e}\"\
          )\n    except Exception as e:\n        parsing_errors.append({\"index\"\
          : -1, \"error\": f\"Unexpected error parsing input: {str(e)}\", \"content\"\
          : json_content_strings_input[:1000]})\n        print(f\"Error: Unexpected\
          \ error parsing input: {e}\")\n\n    if not list_of_data_blocks and parsing_errors:\n\
          \         # Return errors as string if significant parsing issues occurred\n\
          \         return {\n            \"result\": f\"Error during input parsing:\\\
          n```json\\n{json.dumps(parsing_errors, ensure_ascii=False, indent=2)}\\\
          n```\",\n            \"parsing_errors\": json.dumps(parsing_errors, ensure_ascii=False,\
          \ indent=2),\n            \"generation_errors\": json.dumps(generation_errors,\
          \ ensure_ascii=False, indent=2)\n        }\n\n    # 2. Generate ECharts\
          \ configurations using the parsed list\n    final_echarts_outputs = [] #\
          \ Stores dicts {'chart_id': ..., 'output': '```echarts...```'}\n    colors\
          \ = ['#5470c6', '#91cc75', '#fac858', '#ee6666', '#73c0de', '#3ba272', '#fc8452',\
          \ '#9a60b4', '#ea7ccc']\n\n    for block_index, data_block in enumerate(list_of_data_blocks):\n\
          \        charts_list = data_block.get('charts', [])\n        for chart_index,\
          \ chart in enumerate(charts_list):\n            try:\n                chart_id\
          \ = chart.get('chart_id')\n                title = chart.get('title', 'Untitled\
          \ Chart')\n                chart_type = chart.get('type')\n            \
          \    chart_data = chart.get('data')\n\n                if not isinstance(chart,\
          \ dict): raise ValueError(\"Chart item is not a dictionary.\")\n       \
          \         if not isinstance(chart_data, dict): raise ValueError(f\"Chart\
          \ 'data' field is missing or not a dictionary.\")\n                if not\
          \ all([chart_id, chart_type]): raise ValueError(f\"Chart definition missing\
          \ required fields (chart_id, type)\")\n\n                # --- ECharts Config\
          \ Generation Logic (Keep as is) ---\n                echarts_config = {\n\
          \                    \"color\": colors,\n                    \"title\":\
          \ {\"text\": title, \"left\": \"center\", \"textStyle\": {\"fontSize\":\
          \ 16}},\n                    \"tooltip\": {\"trigger\": \"item\" if chart_type\
          \ == \"pie\" else \"axis\"},\n                    \"legend\": { \"show\"\
          : True, \"type\": \"scroll\", \"orient\": \"horizontal\", \"left\": \"center\"\
          , \"bottom\": 5 },\n                    \"grid\": { \"left\": '3%', \"right\"\
          : '4%', \"bottom\": '10%', \"containLabel\": True }\n                }\n\
          \n                # Line Chart\n                if chart_type == \"line\"\
          :\n                    labels = chart_data.get('labels', []); datasets =\
          \ chart_data.get('datasets', [])\n                    if not isinstance(labels,\
          \ list) or not isinstance(datasets, list): raise ValueError(\"'labels'/'datasets'\
          \ must be lists for line chart\")\n                    if not labels or\
          \ not datasets: raise ValueError(\"Missing 'labels'/'datasets' for line\
          \ chart\")\n                    echarts_config[\"xAxis\"] = {\"type\": \"\
          category\", \"boundaryGap\": False, \"data\": labels}; echarts_config[\"\
          yAxis\"] = {\"type\": \"value\"}\n                    legend_data = [ds.get('label',\
          \ f'S{i+1}') for i, ds in enumerate(datasets) if isinstance(ds, dict)]\n\
          \                    echarts_config[\"legend\"][\"data\"] = legend_data\n\
          \                    echarts_config[\"series\"] = []\n                 \
          \   for i, ds in enumerate(datasets):\n                        if not isinstance(ds,\
          \ dict): continue\n                        echarts_config[\"series\"].append({\"\
          name\": ds.get('label', f'S{i+1}'), \"type\": \"line\", \"stack\": None,\
          \ \"smooth\": True, \"data\": ds.get('values', []) if isinstance(ds.get('values'),\
          \ list) else [] })\n                # Pie Chart\n                elif chart_type\
          \ == \"pie\":\n                    labels = chart_data.get('labels', []);\
          \ values = []\n                    pie_datasets = chart_data.get('datasets',\
          \ [])\n                    if 'values' in chart_data and isinstance(chart_data['values'],\
          \ list): values = chart_data['values']\n                    elif isinstance(pie_datasets,\
          \ list) and len(pie_datasets) > 0 and isinstance(pie_datasets[0], dict):\n\
          \                        if 'values' in pie_datasets[0] and isinstance(pie_datasets[0]['values'],\
          \ list): values = pie_datasets[0]['values']\n                        else:\
          \ raise ValueError(\"Pie 'datasets' missing 'values' list\")\n         \
          \           if not isinstance(labels, list): raise ValueError(\"'labels'\
          \ must be list\");\n                    if not values: raise ValueError(\"\
          No 'values' found\");\n                    if len(labels) != len(values):\
          \ raise ValueError(f\"Label/Value mismatch: {len(labels)}!={len(values)}\"\
          )\n                    echarts_config[\"tooltip\"][\"formatter\"] = \"{b}\
          \ : {c} ({d}%)\"\n                    echarts_config[\"legend\"][\"orient\"\
          ] = \"vertical\"; echarts_config[\"legend\"][\"left\"] = \"right\"; echarts_config[\"\
          legend\"][\"top\"] = \"center\"\n                    echarts_config[\"legend\"\
          ][\"data\"] = labels\n                    echarts_config.pop(\"grid\", None)\n\
          \                    echarts_config[\"series\"] = [{\"name\": title, \"\
          type\": \"pie\", \"radius\": ['40%', '70%'], \"avoidLabelOverlap\": False,\
          \ \"itemStyle\": {\"borderRadius\": 10, \"borderColor\": '#fff', \"borderWidth\"\
          : 2},\"label\": {\"show\": False, \"position\": 'center'},\"emphasis\":\
          \ {\"label\": {\"show\": True, \"fontSize\": 20, \"fontWeight\": 'bold'}},\"\
          labelLine\": {\"show\": False},\"data\": [{\"value\": val, \"name\": label}\
          \ for label, val in zip(labels, values)]}]\n                # Bar Chart\n\
          \                elif chart_type == \"bar\":\n                    labels\
          \ = chart_data.get('labels', []); datasets = chart_data.get('datasets',\
          \ [])\n                    if not isinstance(labels, list) or not isinstance(datasets,\
          \ list): raise ValueError(\"'labels'/'datasets' must be lists for bar chart\"\
          )\n                    if not labels or not datasets: raise ValueError(\"\
          Missing 'labels'/'datasets' for bar chart\")\n                    echarts_config[\"\
          xAxis\"] = {\"type\": \"category\", \"data\": labels}; echarts_config[\"\
          yAxis\"] = {\"type\": \"value\"}\n                    legend_data = [ds.get('label',\
          \ f'S{i+1}') for i, ds in enumerate(datasets) if isinstance(ds, dict)]\n\
          \                    echarts_config[\"legend\"][\"data\"] = legend_data\n\
          \                    echarts_config[\"series\"] = []\n                 \
          \   for i, ds in enumerate(datasets):\n                         if not isinstance(ds,\
          \ dict): continue\n                         echarts_config[\"series\"].append({\"\
          name\": ds.get('label', f'S{i+1}'), \"type\": \"bar\", \"barWidth\": \"\
          60%\", \"data\": ds.get('values', []) if isinstance(ds.get('values'), list)\
          \ else [] })\n                else:\n                    raise ValueError(f\"\
          Unsupported chart type: '{chart_type}'\")\n                # --- End ECharts\
          \ Config Generation ---\n\n                output_string = \"```echarts\\\
          n\" + json.dumps(echarts_config, indent=2, ensure_ascii=False) + \"\\n```\"\
          \n                final_echarts_outputs.append({\"chart_id\": chart_id,\
          \ \"output\": output_string}) # Store the dict containing the string\n\n\
          \            except (ValueError, KeyError, TypeError, IndexError) as e:\n\
          \                generation_errors.append({\"block_index\": block_index,\
          \ \"chart_index\": chart_index, \"chart_id\": chart.get('chart_id', 'unknown'),\
          \ \"error\": f\"Error generating ECharts config: {str(e)}\", \"chart_data\"\
          : chart })\n                print(f\"Warning: Could not generate ECharts\
          \ config for chart '{chart.get('chart_id', 'unknown')}' in block {block_index},\
          \ chart index {chart_index}: {e}\")\n\n    # --- MODIFIED PART: Concatenate\
          \ outputs into a single string ---\n    # Extract just the 'output' strings\
          \ (```echarts...```) from the results\n    echarts_markdown_blocks = [item['output']\
          \ for item in final_echarts_outputs]\n\n    # Join these blocks together\
          \ with double newlines\n    final_markdown_string = \"\\n\\n\".join(echarts_markdown_blocks)\n\
          \n    # Optionally, add error information to the final string if needed\
          \ for debugging\n    if generation_errors:\n        final_markdown_string\
          \ += \"\\n\\n---\\n**Generation Errors:**\\n```json\\n\" + json.dumps(generation_errors,\
          \ ensure_ascii=False, indent=2) + \"\\n```\"\n    if parsing_errors:\n \
          \        final_markdown_string += \"\\n\\n---\\n**Parsing Errors:**\\n```json\\\
          n\" + json.dumps(parsing_errors, ensure_ascii=False, indent=2) + \"\\n```\"\
          \n\n    # Return dictionary where the value for \"result\" MUST be the concatenated\
          \ string\n    return {\n        \"result\": final_markdown_string\n    }"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: string
        selected: false
        title: ‰ª£Á†ÅÊâßË°å 2
        type: code
        variables:
        - value_selector:
          - '1745823859913'
          - result
          variable: json_content_strings_input
      height: 54
      id: '1745819871323'
      position:
        x: 1630.3293386439177
        y: 285.90707419604496
      positionAbsolute:
        x: 1630.3293386439177
        y: 285.90707419604496
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        code: "import json\nimport re\n\ndef main(markdown_text: str)-> dict:\n  \
          \  \"\"\"\n    Extracts markdown content after '</think>', finds all JSON\
          \ blocks\n    within ```json ... ```, parses them, and returns the parsed\
          \ data.\n    \"\"\"\n    #markdown_text = markdown_text.decode('utf-8')AttributeError:\
          \ 'str' object has no attribute 'decode'\n    # --- Extract relevant content\
          \ after </think> ---\n    # Use a more robust pattern for <think> block\
          \ removal if needed\n    think_pattern = r'</think>\\s*(.*)'\n    match\
          \ = re.search(think_pattern, markdown_text, re.DOTALL | re.IGNORECASE)\n\
          \    if match:\n        markdown_content = match.group(1).strip()\n    \
          \    print(\"Â∑≤ÊèêÂèñ </think> ‰πãÂêéÁöÑÂÜÖÂÆπ„ÄÇ\")\n    else:\n        print(\"Êú™ÊâæÂà∞ </think>\
          \ Ê†áÁ≠æÔºåÂ∞Ü‰ΩøÁî®ÂÖ®ÈÉ®ÂÜÖÂÆπ‰Ωú‰∏∫ Markdown„ÄÇ\")\n        markdown_content = markdown_text.strip()\n\
          \n    # --- Clean potential leading/trailing ```markdown fence ---\n   \
          \ # Optional: Useful if the input might incorrectly wrap everything\n  \
          \  markdown_content = re.sub(r'^\\s*```markdown\\s*\\n?', '', markdown_content,\
          \ flags=re.IGNORECASE)\n    markdown_content = re.sub(r'\\n?\\s*```\\s*$',\
          \ '', markdown_content)\n    inputmarkdown = markdown_content.strip() #\
          \ Use this variable for consistency\n\n    # --- Initialize lists ---\n\
          \    parsed_data_list = []\n    errors = []\n\n    # --- Pattern for JSON\
          \ blocks (only one capture group needed) ---\n    json_block_pattern = r'```json\\\
          n(.*?)\\n```'\n\n    # --- Iterate through found JSON blocks and parse ---\n\
          \    block_index = 0 # Use 0-based index for consistency with lists\n  \
          \  for match in re.finditer(json_block_pattern, inputmarkdown, re.DOTALL):\n\
          \        # Group 1 contains the content BETWEEN the delimiters\n       \
          \ json_content_str = match.group(1).strip() # Get content from group 1\n\
          \n        try:\n            # Skip if the extracted content is empty after\
          \ stripping\n            if not json_content_str:\n                print(f\"\
          Warning: Skipping empty JSON block content at match index {block_index}.\"\
          )\n                continue\n\n            # Parse the extracted JSON string\n\
          \            json_data = json.loads(json_content_str)\n            parsed_data_list.append(json_data)\
          \ # Append the parsed Python object\n\n        except json.JSONDecodeError\
          \ as json_e:\n            # Handle JSON parsing errors\n            print(f\"\
          Warning: JSON Decode Error at match index {block_index}: {json_e}\")\n \
          \           errors.append({\"index\": block_index, \"error\": f\"JSONDecodeError:\
          \ {str(json_e)}\", \"content\": json_content_str})\n        except Exception\
          \ as e:\n            # Catch any other unexpected errors during processing\n\
          \            print(f\"Warning: General Error processing match index {block_index}:\
          \ {e}\")\n            errors.append({\"index\": block_index, \"error\":\
          \ f\"General Error: {str(e)}\", \"content\": json_content_str})\n\n    \
          \    block_index += 1 # Increment index for error reporting\n\n    # ---\
          \ Return the parsed data (as Python list) and any errors ---\n    # Dify\
          \ will automatically serialize this dictionary to JSON for output.\n   \
          \ # Returning the list of objects is generally more useful for downstream\
          \ nodes\n    # than returning \n    resultstring = json.dumps(parsed_data_list)\n\
          \    return {\n        \"result\": resultstring,  \n        \n    }"
        code_language: python3
        desc: ''
        outputs:
          result:
            children: null
            type: string
        selected: false
        title: ‰ª£Á†ÅÊâßË°å
        type: code
        variables:
        - value_selector:
          - llm
          - text
          variable: markdown_text
      height: 54
      id: '1745823859913'
      position:
        x: 1254.4268732415803
        y: 351
      positionAbsolute:
        x: 1254.4268732415803
        y: 351
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    - data:
        answer: '{{#1745819871323.result#}}'
        desc: ''
        selected: false
        title: Áõ¥Êé•ÂõûÂ§ç 2
        type: answer
        variables: []
      height: 105
      id: '1745895911042'
      position:
        x: 1934.3293386439177
        y: 285.90707419604496
      positionAbsolute:
        x: 1934.3293386439177
        y: 285.90707419604496
      selected: false
      sourcePosition: right
      targetPosition: left
      type: custom
      width: 244
    viewport:
      x: -239.6697666312839
      y: 302.01821206898654
      zoom: 0.4550194120404505
